good afternoon everyone。 i‘m hongchi zhou。 my topic is baysian variational inference based on spsa
my presentation includes 5 parts：5个。
Bayesian inference is a powerful framework that allows us to quantify uncertainty in modeling.
Traditionally, we rely on MCMC methods to sample from the posterior, but these become computationally expensive, especially in high-dimensional settings.
To address this, we turn to Variational Bayes, which reframes inference as an optimization problem,avoiding sampling.
However, the objective function VB optimizes — is often highly complex, making its gradient hard or even infeasible to compute.
This motivates the use of gradient-free methods. Simultaneous Perturbation Stochastic Approximation (SPSA) is one such method, well-suited for noisy, high-dimensional optimization problems.
In this work, we explore the combination of SPSA and Variational Bayes to perform efficient Bayesian inference 

The prior p(\theta) encodes our beliefs or domain knowledge about parameters

The main optimization algorithm we use is SPSA, but in practice, its decaying step size can cause it to get stuck before reaching the optimum. To address this, we incorporate Adam to adaptively scale updates and maintain momentum.